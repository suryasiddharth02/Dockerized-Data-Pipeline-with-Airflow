ğŸ“ˆ Dockerized Stock Market Data Pipeline (Airflow + PostgreSQL)

A fully containerized ETL pipeline that automatically fetches stock market data, processes it, and stores it in PostgreSQL â€” all orchestrated with Apache Airflow, running entirely inside Docker Compose.

This project is designed for reliability, modularity, and easy deployment.

ğŸš€ Features

Dockerized orchestration using Airflow

Automated scheduled pipeline (daily or hourly)

Fetches real-time stock data from Alpha Vantage (or optional Yahoo Finance)

Parses JSON response and stores data in a PostgreSQL table

Environment variables for secure secrets management

Built-in error handling and retry logic

Persistent database storage

Clean, scalable project structure

ğŸ“ Project Structure
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ stock_pipeline_dag.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ fetch_and_store.py
â””â”€â”€ README.md

ğŸ› ï¸ Prerequisites

You must have installed:

Docker

Docker Compose

Internet connection (to fetch stock API data)

Verify:

docker --version
docker compose version

ğŸ”§ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/your-repo.git
cd your-repo

2ï¸âƒ£ Create a .env File

In your project root, create .env containing:

POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=stock_pipeline

STOCK_API_KEY=YOUR_ALPHA_VANTAGE_KEY
FERNET_KEY=YOUR_GENERATED_FERNET_KEY

Get an Alpha Vantage API key (free)

ğŸ‘‰ https://www.alphavantage.co/support/#api-key

Generate a Fernet Key

Airflow requires this for encryption:

python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

3ï¸âƒ£ Start the Entire Pipeline

Build + start all services:

docker compose up --build


This will:

Start PostgreSQL

Initialize Airflow DB

Create Airflow admin user

Start Webserver + Scheduler

Load your DAG

ğŸŒ Airflow Web UI

Once running, open:

ğŸ‘‰ http://localhost:8080

Default Credentials:

Username: admin

Password: admin

â–¶ï¸ Running the Stock Pipeline

Inside Airflow:

Find the DAG: stock_pipeline_dag

Toggle it ON

Click â–¶ Run to trigger manually OR wait for scheduled time

ğŸ“Š Viewing Stored Stock Data

Connect to PostgreSQL inside Docker:

docker exec -it postgres psql -U airflow -d stock_pipeline


Query the table:

SELECT * FROM stock_data;

ğŸ§¹ Stopping & Cleaning Up

To stop all containers:

CTRL + C
docker compose down


To remove containers + database data:

docker compose down -v

ğŸ› Troubleshooting
âŒ Airflow exited with code 1

âœ” Likely wrong Fernet key or DB issue
âœ” Try deleting volumes:

docker compose down -v
docker compose up --build

âŒ Airflow UI not opening

Check port:

lsof -i :8080

ğŸ§© Optional: Yahoo Finance Version (No API Key Needed)

If you prefer a version without API keys, replace the fetch script with:

import yfinance as yf


Ask and I will generate the full Yahoo-Finance version.

ğŸ“œ License

MIT License â€” free to use, modify, and distribute.

ğŸ™Œ Contribution

Pull requests are welcome. For major changes, open an issue first to discuss what youâ€™d like to change.
